{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studio preliminare su MobileNetV2\n",
    "Inizialmente si era tentato di utilizzare MobileNetV2 e provare a quantizzare la rete per poi effettuare un confronto finale sui vari metodi di quantizzazione o meno.\n",
    "Tuttavia dopo aver addestrato con successo la rete e quantizzato i modelli nei tre modi possibili (dinamico, statico, aware training) le performance delle reti risultavano essere le medesime e quindi si Ã¨ scartata questa opzione andando ad impiegare il modello MobileNetV3 presente nel file train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# Specify random seed for repeatable results\n",
    "torch.manual_seed(191009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import QuantStub, DeQuantStub\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class ConvBNReLU(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_planes, momentum=0.1),\n",
    "            # Replace with ReLU\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
    "        layers.extend([\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup, momentum=0.1),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        # Replace torch.add with floatfunctional\n",
    "        self.skip_add = nn.quantized.FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return self.skip_add.add(x, self.conv(x))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
    "        \"\"\"\n",
    "        MobileNet V2 main class\n",
    "        Args:\n",
    "            num_classes (int): Number of classes\n",
    "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
    "            inverted_residual_setting: Network structure\n",
    "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
    "            Set to 1 to turn off rounding\n",
    "        \"\"\"\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "\n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 16, 1, 1],\n",
    "                [6, 24, 2, 2],\n",
    "                [6, 32, 3, 2],\n",
    "                [6, 64, 4, 2],\n",
    "                [6, 96, 3, 1],\n",
    "                [6, 160, 3, 2],\n",
    "                [6, 320, 1, 1],\n",
    "            ]\n",
    "\n",
    "        # only check the first element, assuming user knows t,c,n,s are required\n",
    "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
    "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
    "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
    "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
    "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.features(x)\n",
    "        x = x.mean([2, 3])\n",
    "        x = self.classifier(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    # Fuse Conv+BN and Conv+BN+Relu modules prior to quantization\n",
    "    def fuse_model(self):\n",
    "        fuse_modules = torch.quantization.fuse_modules\n",
    "        for m in self.modules():\n",
    "            if type(m) == ConvBNReLU:\n",
    "                fuse_modules(m, ['0', '1', '2'], inplace=True)\n",
    "            if type(m) == InvertedResidual:\n",
    "                for idx in range(len(m.conv)):\n",
    "                    if type(m.conv[idx]) == nn.Conv2d:\n",
    "                        fuse_modules(m.conv, [str(idx), str(idx + 1)], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_file):\n",
    "    model = MobileNetV2()\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(1280, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 2)\n",
    "    )\n",
    "\n",
    "    model.to('cpu')\n",
    "    return model\n",
    "\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\") / 1e6)\n",
    "    os.remove('temp.p')\n",
    "\n",
    "\n",
    "def load_model(model_file):\n",
    "    model = MobileNetV2()\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    #freeze all the other layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(1280, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(512, 2)\n",
    "    )\n",
    "\n",
    "    model.to('cpu')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, num_epochs=3):\n",
    "    device = 'cpu'    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        model.to(device)\n",
    "        \n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(torch.float32).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "saved_model_dir = 'models\\\\'\n",
    "float_model_file = 'mobilenet_pretrained_float.pth'\n",
    "scripted_float_model_file = 'mobilenet_quantization_scripted.pth'\n",
    "scripted_quantized_model_file = 'mobilenet_quantization_scripted_quantized.pth'\n",
    "\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 32\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "input_path = 'data\\\\'\n",
    "augmented_path1 = 'data_aug\\\\'\n",
    "augmented_path2 = 'data_aug2\\\\'\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(input_path + 'validation', data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(input_path + 'test', data_transforms['test'])\n",
    "}\n",
    "\n",
    "\n",
    "augmented1_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(augmented_path1, 'train'), data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(os.path.join(augmented_path1, 'validation'), data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(os.path.join(augmented_path1, 'test'), data_transforms['test'])\n",
    "}\n",
    "\n",
    "augmented2_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(augmented_path2, 'train'), data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(os.path.join(augmented_path2, 'validation'), data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(os.path.join(augmented_path2, 'test'), data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Combina i dataset originali e aumentati\n",
    "combined_datasets = {\n",
    "    'train': ConcatDataset([image_datasets['train'], augmented1_datasets['train'], augmented2_datasets['train']]),\n",
    "    'validation': ConcatDataset([image_datasets['validation'], augmented1_datasets['validation'], augmented2_datasets['validation']]),\n",
    "    'test': ConcatDataset([image_datasets['test'], augmented1_datasets['test'], augmented2_datasets['test']])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(combined_datasets['train'], batch_size=32, shuffle=True, num_workers=0),\n",
    "    'validation': torch.utils.data.DataLoader(combined_datasets['validation'], batch_size=32, shuffle=False, num_workers=0),\n",
    "    'test': torch.utils.data.DataLoader(combined_datasets['test'], batch_size=1, shuffle=False, num_workers=0)\n",
    "}\n",
    "\n",
    "data_loader, data_loader_test = dataloaders['train'],dataloaders['validation']\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "float_model = load_model(saved_model_dir + float_model_file).to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of baseline model\")\n",
    "print_size_of_model(float_model)\n",
    "\n",
    "model_trained = train_model(float_model, num_epochs=9)\n",
    "\n",
    "torch.save(model_trained.to('cpu').state_dict(), 'model.pt')\n",
    "torch.jit.save(torch.jit.script(model_trained.to('cpu')), 'float_script.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "x = models.quantization.mobilenet_v3_large(pretrained=True)\n",
    "x.classifier = nn.Sequential(\n",
    "    nn.Linear(960, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "print_size_of_model(x.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "myModel = x.to('cpu')\n",
    "myModel.eval()\n",
    "\n",
    "myModel.fuse_model()\n",
    "\n",
    "myModel.qconfig = torch.quantization.get_default_qconfig('x86')\n",
    "print(myModel.qconfig)\n",
    "torch.quantization.prepare(myModel)\n",
    "\n",
    "#calibration\n",
    "for inputs, labels in dataloaders['validation']:\n",
    "    myModel(inputs)\n",
    "print('Post Training Quantization: Calibration done')\n",
    "\n",
    "torch.quantization.convert(myModel.to('cpu'))\n",
    "\n",
    "print(\"Size of model after quantization\")\n",
    "print_size_of_model(myModel.to('cpu'))\n",
    "torch.jit.save(torch.jit.script(model_trained.to('cpu')), 'staticq_script.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = MobileNetV2()\n",
    "\n",
    "x.classifier = nn.Sequential(\n",
    "    nn.Linear(1280, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "x.to('cpu')\n",
    "x.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qat_model = x.to('cpu')\n",
    "qat_model.fuse_model()\n",
    "\n",
    "qat_model.qconfig = torch.quantization.get_default_qat_qconfig('x86')\n",
    "\n",
    "torch.quantization.prepare_qat(qat_model)\n",
    "\n",
    "qat_model = train_model(qat_model,3)\n",
    "\n",
    "qat_model.eval()\n",
    "torch.quantization.convert(qat_model.to('cpu'))\n",
    "torch.jit.save(torch.jit.script(qat_model.to('cpu')), 'qat_script.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def test_models(model_dynamicq, model_staticq, model_qat, test_dataloader):\n",
    "    models = [model_dynamicq, model_staticq, model_qat]\n",
    "    model_names = ['Automatic Optimization', 'Static Quantization', 'Quantization Aware Training']\n",
    "\n",
    "    accuracies = []\n",
    "    inference_times = []\n",
    "\n",
    "    for model, model_name in zip(models, model_names):\n",
    "        model.eval()\n",
    "        model.to('cpu')\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        i = 0\n",
    "        avg_time = 0\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # Run inference\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            i += len(inputs)\n",
    "            avg_time += (end_time - start_time)\n",
    "\n",
    "            # Calculate average inference time for every 10 images\n",
    "            if i % 30 == 0:\n",
    "                inference_time = avg_time / 10 * 1e3  # Convert to microseconds\n",
    "                inference_times.append(inference_time)\n",
    "                avg_time = 0  # Reset average time\n",
    "\n",
    "        # Calculate accuracy for the entire test set\n",
    "        accuracy = correct / total\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "        # Check if inference_times is not empty before calculating the average\n",
    "        if inference_times:\n",
    "            print(f\"Accuracy of {model_name} on the test set: {accuracy:.4f}\")\n",
    "            print(f\" - Average Inference Time: {sum(inference_times)/len(inference_times):.2f} milliseconds per 10 images\\n\")\n",
    "\n",
    "    return accuracies, inference_times\n",
    "\n",
    "\n",
    "# Replace these with your actual models\n",
    "model_automatic_optimization = torch.jit.load('optimized_model.pt')\n",
    "model_staticq_path = torch.jit.load('script.pt')\n",
    "model_qat_path = torch.jit.load('model_qat.pt')\n",
    "\n",
    "\n",
    "accuracies, inference_times = test_models(model_automatic_optimization, model_staticq_path, model_qat_path, dataloaders['test'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaghetti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
