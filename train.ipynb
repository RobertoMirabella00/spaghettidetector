{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.quantization import QuantStub, DeQuantStub, fuse_modules, quantize_dynamic\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42  \n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module is responsible for creating the train, validation and test splits.\n",
    "In particular, it creates 3 JSONs, and each of them contains an array with the paths\n",
    "where the imgs are located.\n",
    "\"\"\"\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "def cycle_path(nerfs_root):\n",
    "    \n",
    "\n",
    "    dict_result = {}\n",
    "\n",
    "    last_two_parts = os.path.join(*os.path.splitdrive(nerfs_root)[1].split(os.sep)[-2:])\n",
    "    base_folder = os.path.join('.', last_two_parts)\n",
    "\n",
    "    for class_name in os.listdir(nerfs_root):\n",
    "\n",
    "        class_nerf_paths = []\n",
    "\n",
    "        subject_dirs = os.path.join(nerfs_root, class_name)\n",
    "\n",
    "        if not os.path.isdir(subject_dirs):\n",
    "            continue\n",
    "        \n",
    "        for subject_name in os.listdir(subject_dirs):\n",
    "            subject_dir = os.path.join(subject_dirs, subject_name)\n",
    "            class_nerf_paths.append(subject_dir.replace(nerfs_root, base_folder))        \n",
    "        dict_result[class_name] = class_nerf_paths\n",
    "\n",
    "    return dict_result\n",
    "\n",
    "\n",
    "def create():\n",
    "    root_paths = ['archive']\n",
    "\n",
    "    train = []\n",
    "    validation = []\n",
    "    test = []\n",
    "\n",
    "    TRAIN_SPLIT = 80\n",
    "    VALIDATION_SPLIT = 10\n",
    "    TEST_SPLIT = 10\n",
    "\n",
    "    random.seed(1203)\n",
    "\n",
    "    for curr_path in root_paths:\n",
    "        \n",
    "        # Get \n",
    "        nerfs_dict = cycle_path(curr_path)\n",
    "\n",
    "        for class_name in nerfs_dict:\n",
    "\n",
    "            # Get elements related to the current class\n",
    "            class_elements = nerfs_dict[class_name]\n",
    "            random.shuffle(class_elements)\n",
    "            \n",
    "            n_elements = len(class_elements)\n",
    "\n",
    "            # Define the dimensions of the splits\n",
    "            n_test = math.floor(n_elements * TEST_SPLIT / 100)\n",
    "            n_validation = math.floor(n_elements * VALIDATION_SPLIT / 100)\n",
    "            n_train = n_elements - n_validation - n_test\n",
    "\n",
    "            # Make the splits according to their sizes\n",
    "            train_elements = class_elements[0:n_train]\n",
    "            validation_elements = class_elements[n_train:n_train+n_validation]\n",
    "            test_elements = class_elements[n_train+n_validation:]\n",
    "            \n",
    "            # Length validation\n",
    "            total_elements = len(train_elements) + len(validation_elements) + len(test_elements)\n",
    "            assert total_elements == n_elements and n_test > 0 and n_validation > 0 and n_train > 0, 'Not all elements were properly used.'\n",
    "\n",
    "            # Elements uniqueness validation\n",
    "            set1 = set(train_elements)\n",
    "            set2 = set(validation_elements)\n",
    "            set3 = set(test_elements)\n",
    "\n",
    "            no_common_elements = set1.isdisjoint(set2) and set1.isdisjoint(set3) and set2.isdisjoint(set3)\n",
    "            assert not no_common_elements == n_elements, 'Some elements are shared between splits'\n",
    "\n",
    "            train = train + train_elements\n",
    "            validation = validation + validation_elements\n",
    "            test = test + test_elements\n",
    "    \n",
    "    with open(os.path.join('train.json'), 'w') as file:\n",
    "        json.dump(train, file)\n",
    "    with open(os.path.join('validation.json'), 'w') as file:\n",
    "        json.dump(validation, file)\n",
    "    with open(os.path.join('test.json'), 'w') as file:\n",
    "        json.dump(test, file)\n",
    "    \n",
    "#create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def organize_images(source_paths, base_folder, split):\n",
    "\n",
    "    for source_path in source_paths:\n",
    "        if 'no_defected' in source_path:\n",
    "            destination_folder = os.path.join(base_folder, split, 'no_defected')\n",
    "        else:\n",
    "            destination_folder = os.path.join(base_folder, split, 'defected')\n",
    "        os.makedirs(destination_folder, exist_ok=True)\n",
    "        filename = os.path.basename(source_path)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "        shutil.copy(source_path, destination_path)\n",
    "\n",
    "\"\"\"with open('train.json', 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "\n",
    "with open('validation.json', 'r') as file:\n",
    "    validation_data = json.load(file)\n",
    "\n",
    "with open('test.json', 'r') as file:\n",
    "    test_data = json.load(file)\"\"\"\n",
    "\n",
    "base_folder = 'archive'\n",
    "\n",
    "#organize_images(train_data, base_folder, 'train')\n",
    "\n",
    "#organize_images(validation_data, base_folder, 'validation')\n",
    "\n",
    "#organize_images(test_data, base_folder, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "base_path = 'data'\n",
    "output_path = 'data_aug2'\n",
    "\n",
    "shutil.rmtree(output_path, ignore_errors=True)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "\"\"\"\n",
    "def augment_images_in_folder(input_folder, output_folder):\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        input_class_folder_path = os.path.join(input_folder, class_folder)\n",
    "        output_class_folder_path = os.path.join(output_folder, class_folder)\n",
    "        os.makedirs(output_class_folder_path, exist_ok=True)\n",
    "\n",
    "        for image_name in os.listdir(input_class_folder_path):\n",
    "            input_image_path = os.path.join(input_class_folder_path, image_name)\n",
    "            output_image_path = os.path.join(output_class_folder_path, image_name)\n",
    "\n",
    "            # Carica l'immagine\n",
    "            image = cv2.imread(input_image_path)\n",
    "\n",
    "            # Converte l'immagine in bianco e nero\n",
    "            grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Salva l'immagine in bianco e nero nella cartella di output\n",
    "            cv2.imwrite(output_image_path, grayscale_image)\n",
    "\"\"\"\n",
    "\n",
    "def augment_images_in_folder(input_folder, output_folder):\n",
    "    for class_folder in os.listdir(input_folder):\n",
    "        input_class_folder_path = os.path.join(input_folder, class_folder)\n",
    "        output_class_folder_path = os.path.join(output_folder, class_folder)\n",
    "        os.makedirs(output_class_folder_path, exist_ok=True)\n",
    "\n",
    "        for image_name in os.listdir(input_class_folder_path):\n",
    "            input_image_path = os.path.join(input_class_folder_path, image_name)\n",
    "            output_image_path = os.path.join(output_class_folder_path, image_name)\n",
    "\n",
    "            image = cv2.imread(input_image_path)\n",
    "\n",
    "            sepia_matrix = np.array([[0.393, 0.769, 0.189],\n",
    "                                     [0.349, 0.686, 0.168],\n",
    "                                     [0.272, 0.534, 0.131]])\n",
    "\n",
    "            sepia_image = cv2.transform(image, sepia_matrix)\n",
    "\n",
    "            sepia_image = np.clip(sepia_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(output_image_path, sepia_image)\n",
    "\n",
    "augment_images_in_folder(os.path.join(base_path, 'train'), os.path.join(output_path, 'train'))\n",
    "augment_images_in_folder(os.path.join(base_path, 'validation'), os.path.join(output_path, 'validation'))\n",
    "augment_images_in_folder(os.path.join(base_path, 'test'), os.path.join(output_path, 'test'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "input_path = 'data\\\\'\n",
    "augmented_path1 = 'data_aug\\\\'\n",
    "augmented_path2 = 'data_aug2\\\\'\n",
    "data_transforms = {\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'validation':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "    'test':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    'train': datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(input_path + 'validation', data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(input_path + 'test', data_transforms['test'])\n",
    "}\n",
    "\n",
    "\n",
    "augmented1_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(augmented_path1, 'train'), data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(os.path.join(augmented_path1, 'validation'), data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(os.path.join(augmented_path1, 'test'), data_transforms['test'])\n",
    "}\n",
    "\n",
    "augmented2_datasets = {\n",
    "    'train': datasets.ImageFolder(os.path.join(augmented_path2, 'train'), data_transforms['train']),\n",
    "    'validation': datasets.ImageFolder(os.path.join(augmented_path2, 'validation'), data_transforms['validation']),\n",
    "    'test': datasets.ImageFolder(os.path.join(augmented_path2, 'test'), data_transforms['test'])\n",
    "}\n",
    "\n",
    "# Combina i dataset originali e aumentati\n",
    "combined_datasets = {\n",
    "    'train': ConcatDataset([image_datasets['train'], augmented1_datasets['train'], augmented2_datasets['train']]),\n",
    "    'validation': ConcatDataset([image_datasets['validation'], augmented1_datasets['validation'], augmented2_datasets['validation']]),\n",
    "    'test': ConcatDataset([image_datasets['test'], augmented1_datasets['test'], augmented2_datasets['test']])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(combined_datasets['train'], batch_size=32, shuffle=True, num_workers=0),\n",
    "    'validation': torch.utils.data.DataLoader(combined_datasets['validation'], batch_size=32, shuffle=False, num_workers=0),\n",
    "    'test': torch.utils.data.DataLoader(combined_datasets['test'], batch_size=1, shuffle=False, num_workers=0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.mobilenet_v3_large(pretrained=True).to(device)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(960, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 2) \n",
    ").to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs=3):\n",
    "        \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        model.to(device)\n",
    "        \n",
    "        for phase in ['train', 'validation']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(torch.float32).to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(combined_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(combined_datasets[phase])\n",
    "\n",
    "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
    "                                                        epoch_loss,\n",
    "                                                        epoch_acc))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = train_model(model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "torchscript_model = torch.jit.script(model_trained)\n",
    "optimized_model = optimize_for_mobile(torchscript_model)\n",
    "optimized_model.save(\"optimized_model.pt\")\n",
    "torchscript_model.save(\"script.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def test_models(model, test_dataloader):\n",
    "\n",
    "    inference_times = []\n",
    "    model.eval()\n",
    "    model.to('cpu')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    i = 0\n",
    "    avg_time = 0\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to('cpu'), labels.to('cpu')\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Run inference\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        i += len(inputs)\n",
    "        avg_time += (end_time - start_time)\n",
    "\n",
    "        # Calculate average inference time for every 10 images\n",
    "        if i % 10 == 0:\n",
    "            inference_time = avg_time / 10 * 1e3  # Convert to microseconds\n",
    "            inference_times.append(inference_time)\n",
    "            avg_time = 0  # Reset average time\n",
    "\n",
    "    # Calculate accuracy for the entire test set\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Check if inference_times is not empty before calculating the average\n",
    "    if inference_times:\n",
    "        print(f\"Accuracy on the test set: {accuracy:.4f}\")\n",
    "        print(f\" - Average Inference Time: {sum(inference_times)/len(inference_times):.2f} milliseconds per image\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_models(torch.jit.load('script.pt'), dataloaders['test'])\n",
    "\n",
    "test_models(torch.jit.load('optimized_model.pt'), dataloaders['test'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08262848854064941\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import time\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "x = torch.jit.load('datasets\\\\runs\\\\detect\\\\train\\\\weights\\\\best.torchscript').to('cpu')\n",
    "#x = torch.jit.load('script.pt').to('cpu')\n",
    "image = Image.open(\"datasets\\\\test\\\\images\\\\148269246_3650105938422073_232258935701890484_n_cropped_jpg.rf.780bbee8eb94051585beb171bc3d56b1.jpg\").resize((224, 224))\n",
    "\n",
    "# Define a transform to apply to the image\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Apply the transform to the image\n",
    "input_tensor = preprocess(image).unsqueeze(0)\n",
    "\n",
    "start = time.time()\n",
    "x(input_tensor)\n",
    "print(time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaghetti",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
